{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo utilizaremos el dataset `cleaned_cuisines.csv` que fue preparado anteriormente en `1.Introduccion` para predecir la nacionalidad de la cocina en base a un grupo de ingredientes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "\n",
    "cuisine_df = pd.read_csv('./data/cleaned_cuisines.csv')\n",
    "cuisines_label_df = cuisine_df['cuisine']\n",
    "cuisines_feature_df = cuisine_df.drop(['Unnamed: 0', 'cuisine'], axis=1)\n",
    "\n",
    "# Separamos los datos en labels y features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing your classifier\n",
    "\n",
    "Scikit-learn groups classification under Supervised Learning, and in that category you will find many ways to classify. The variety is quite bewildering at first sight. The following methods all include classification techniques:\n",
    "\n",
    "- Linear Models\n",
    "- Support Vector Machines\n",
    "- Stochastic Gradient Descent\n",
    "- Nearest Neighbors\n",
    "- Gaussian Processes\n",
    "- Decision Trees\n",
    "- Ensemble methods (voting Classifier)\n",
    "- Multiclass and multioutput algorithms (multiclass and multilabel classification, multiclass-multioutput classification)\n",
    "- You can also use neural networks to classify data, but that is outside the scope of this lesson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What classifier to go with?\n",
    "\n",
    "So, which classifier should you choose? Often, running through several and looking for a good result is a way to test. Scikit-learn offers a [side-by-side comparison](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html) on a created dataset, comparing KNeighbors, SVC two ways, GaussianProcessClassifier, DecisionTreeClassifier, RandomForestClassifier, MLPClassifier, AdaBoostClassifier, GaussianNB and QuadraticDiscrinationAnalysis, showing the results visualized:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A better way than wildly guessing, however, is to follow the ideas on this downloadable [ML Cheat sheet](https://learn.microsoft.com/es-es/azure/machine-learning/algorithm-cheat-sheet?view=azureml-api-1&WT.mc_id=academic-77952-leestott). Here, we discover that, for our multiclass problem, we have some choices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Let's see if we can reason our way through different approaches given the constraints we have:\n",
    "\n",
    "- Neural networks are too heavy. Given our clean, but minimal dataset, and the fact that we are running training locally via notebooks, neural networks are too heavyweight for this task.\n",
    "- No two-class classifier. We do not use a two-class classifier, so that rules out one-vs-all.\n",
    "- Decision tree or logistic regression could work. A decision tree might work, or logistic regression for multiclass data.\n",
    "- Multiclass Boosted Decision Trees solve a different problem. The multiclass boosted decision tree is most suitable for nonparametric tasks, e.g. tasks designed to build rankings, so it is not useful for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.7981651376146789\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)\n",
    "\n",
    "# Create a logistic regression with multi_class set to ovr and the solver set to liblinear:\n",
    "lr = LogisticRegression(multi_class=\"ovr\", solver=\"liblinear\")\n",
    "model = lr.fit(X_train, y_train) # np.ravel(y_train)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print (\"Accuracy is {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ingredients: Index(['cayenne', 'cilantro', 'egg', 'onion', 'tomato', 'turmeric',\n",
      "       'vegetable_oil'],\n",
      "      dtype='object')\n",
      "cuisine: indian\n"
     ]
    }
   ],
   "source": [
    "# Printing real data (test values)\n",
    "row = 211\n",
    "print(f'ingredients: {X_test.iloc[row][X_test.iloc[row]!=0].keys()}')\n",
    "print(f'cuisine: {y_test.iloc[row]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\valen\\Documents\\ML-projects\\ML_env\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>indian</th>\n",
       "      <td>0.920791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thai</th>\n",
       "      <td>0.050735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chinese</th>\n",
       "      <td>0.014611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>korean</th>\n",
       "      <td>0.011549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>japanese</th>\n",
       "      <td>0.002313</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0\n",
       "indian    0.920791\n",
       "thai      0.050735\n",
       "chinese   0.014611\n",
       "korean    0.011549\n",
       "japanese  0.002313"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the accuracy of the prediction\n",
    "test= X_test.iloc[row].values.reshape(-1, 1).T\n",
    "proba = model.predict_proba(test)\n",
    "classes = model.classes_\n",
    "resultdf = pd.DataFrame(data=proba, columns=classes)\n",
    "\n",
    "topPrediction = resultdf.T.sort_values(by=[0], ascending = [False])\n",
    "topPrediction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.76      0.74      0.75       250\n",
      "      indian       0.90      0.92      0.91       232\n",
      "    japanese       0.68      0.80      0.74       256\n",
      "      korean       0.84      0.77      0.81       224\n",
      "        thai       0.85      0.76      0.80       237\n",
      "\n",
      "    accuracy                           0.80      1199\n",
      "   macro avg       0.81      0.80      0.80      1199\n",
      "weighted avg       0.80      0.80      0.80      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test,y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
